# SPARK学习

## 简介-大数据

### DIKW金字塔

DIKW体系将数据、信息、知识、智慧纳入到一种金字塔形的层次体系，每一层比下一层都赋予的一些特质。原始观察及量度获得了数据、分析数据间的关系获得了信息。在行动上应用信息产生了知识。智慧关心未来，它含有暗示及滞后影响的意味。

### 大数据3V特征

一个是Volume，数据容量越来越大，第二个是 Velocity，数据量增长越来越快，需要处理的速度和响应的时间越来越快，对系统的延时要求相当高。第三个就是Variety，各种各样类型的数据，过去的数据更多的是结构化的，现在越来越多的数据是半结构，甚至是完全没有结构的数据，从企业里来的、从互联网来的，从用户来的各种各样的数据都大量进入我们的服务器、进入数据中心，所以这里面产生了很多的挑战，这么多数据怎么样把它变成信息，怎么样把信息变成知识，把知识变成决策，这就需要有更多的很好的数据处理能力。

### Lambda架构

Lambda架构划分为三层，分别是批处理层，服务层，和加速层。面向的对象为静态数据和实时数据。

批处理层主用由Hadoop来实现，负责数据的存储和产生随意的视图数据。

服务层是由Cloudera Impala框架来实现的，总体而言，使用了Impala的主要特性。从批处理输出的是一系列包括估计算视图的原始文件。服务层负责建立索引和呈现视图。以便于它们可以被非常好被查询到。Hadoop和Impala是批处理层和服务层极好的工具。

在本质上，加速层与批处理层是一样的，都是从它接受到的数据上计算而得到视图。加速层就是为了弥补批处理层的高延迟性问题，它通过Strom框架计算实时视图来解决问题。因为实时视图是增量的。加速层须要同一时候随机的读和写。为此，我将使用Apache HBase数据库。HBase提供了对Storm连续地增量化实时视图的能力。同一时候，为Impala提供查询经批处理视图合并后得到的结果。Impala查询存储在HDFS中批处理视图和存储在HBase中的实时视图，这使得Impala成为相当完美的工具。

## 简介-Spark

### Hadoop的核心技术

MapReduce:丛集资源管理及资料处理

JobTracker回去和NameNode询问需要处理的资料在那儿。

HDFS:冗余可靠的档案系统

namenode:管理资料分片的状况以及各分片所在地。记录metadata和filesystem。

### Spark核心RDD

RDD为弹性分散式资料集，最基础的抽象结构，可以容忍错误并平行运行。

RDD的两种操作行为：转换和行动。

转换是懒惰操作，不会实时触发。行动是实时操作，会立即执行。

任务切分-宽依赖RDD指的是各个节点之间会有操作，groupByKey,reduceByKey

任务切分-窄依赖RDD指的是不需要和其他节点进行操作，map,filter

### Spark元件

SparkDriver，执行使用者的应用程序，建立SparkContext并且安排任务，与ClusterManager沟通。

Executors,执行Driver排定的工作，执行结果存于Memory,与存储系统互动。

ClusterManager,资源分配与管理。


## 搭建Spark环境




